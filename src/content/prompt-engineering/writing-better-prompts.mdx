---
title: "Writing Better Prompts - Templates, Roles, and Real Examples"
description: "Master advanced prompt engineering techniques with structured templates, role-based prompting, and real-world examples using Google Gemini"
collection: "prompt-engineering"
order: 2
author: "Praveen"
publishDate: 2025-08-08
readTime: "15 min read"
tags:
  [
    "prompt-engineering",
    "templates",
    "roles",
    "gemini",
    "advanced-prompting",
    "personas",
  ]
prerequisites: ["prompt-engineering-101"]
authorProfile:
  github: "https://github.com/PraveenMudalgeri"
---

import TemplateGrid, { TemplateCard } from "../../components/TemplateGrid.tsx";

# Writing Better Prompts - Templates, Roles, and Real Examples

You've learned the basics of prompt engineering. Now it's time to level up. The difference between good and great prompts isn't just clarity—it's structure, roles, and templates that transform your interactions with AI from hit-or-miss to consistently brilliant.

Think of this as your toolkit for prompting like a pro. We'll explore how to use structured templates, assign roles that get AI thinking like experts, and build prompts that work reliably every time. Plus, you'll get hands-on examples using Google Gemini that you can immediately apply to your projects.

---

## Why Structure Matters More Than You Think

Here's the thing: most people treat AI prompts like casual conversations. But the best results come from treating them like precise instructions to a highly skilled assistant.

Structured prompts work because they:

- **Reduce ambiguity**: Clear sections mean clearer results
- **Scale easily**: Once you have a template, you can adapt it for different situations
- **Improve consistency**: Same structure, predictable quality
- **Save time**: No more wrestling with vague outputs

> Tip: Start with a simple prompt skeleton and only add complexity if results are inconsistent.

Let's break down the anatomy of a powerful prompt.

---

## The Four-Part Prompt Template That Actually Works

After testing dozens of approaches, this template consistently delivers the best results:

### Template Structure

- **ROLE**: Who the AI should become
- **TASK**: What you want done
- **CONTEXT**: Background information needed
- **FORMAT**: How you want the output structured

> Note: Use these labels explicitly in your prompts. Treat them like headings so the model understands each section’s purpose.

### Real Example: Content Creation

**Basic Version (Weak):**
"Write about sustainable fashion."

**Template Version (Powerful):**

- **ROLE**: You are a sustainability expert with 10 years of experience in fashion industry consulting.
- **TASK**: Write an engaging blog post about sustainable fashion practices that small clothing brands can actually implement.
- **CONTEXT**: The target audience is startup clothing brand owners with limited budgets who want to become more environmentally conscious. They need practical, actionable advice rather than theory.
- **FORMAT**: Structure as:
  - Hook opening paragraph
  - 5 specific practices with implementation costs
  - One real brand example per practice
  - Action steps conclusion
  - 800–1000 words total

See the difference? The template version gives Gemini everything it needs to create exactly what you want.

> Why this works: You give the model a clear persona, goal, constraints, and output format—reducing ambiguity and boosting consistency.

---

## Role-Based Prompting: Transform AI Into Any Expert

Role prompting is like method acting for AI. When you assign a specific persona, the AI adopts that perspective's knowledge, tone, and approach. This isn't just clever—it's scientifically proven to improve output quality.

### The Expert Framework

Use this formula for expert roles:

> _"You are a [SPECIFIC TITLE] with [YEARS] years of experience in [DOMAIN].
> You specialize in [SPECIALTY] and are known for [UNIQUE APPROACH/STRENGTH]."_

#### Let's see an example for role Code Reviewer to understand what we actually meant...

```python
# Role Setup
role = """
You are a senior Python developer with 5 years of experience in code reviews.
You focus on clean, readable code and practical improvements.
"""

# Task
task = """
Review this function and suggest 3 specific improvements:

def process_users(users):
    result = []
    for u in users:
        if u['status'] == 'active' and u['age'] > 18:
            result.append({'name': u['name'], 'email': u['email']})
    return result

Format as: 1. Issue, 2. Solution, 3. Code example
"""

# Combined prompt
prompt = f"{role}\n\n{task}"
```

---

## Template Library: Proven Patterns for Common Tasks

Here are battle-tested templates you can use immediately:

<TemplateGrid>
  <TemplateCard title="Problem–Solution Template">
    You are a [EXPERT_TYPE] helping solve [PROBLEM_DOMAIN] challenges.

    **Problem:** [SPECIFIC_ISSUE]
    **Constraints:** [LIMITATIONS]
    **Goal:** [DESIRED_OUTCOME]

    **Provide:**
    - Root cause analysis (2-3 key factors)
    - Solution options (rank by feasibility)
    - Implementation roadmap
    - Success metrics

    Format as executive summary with bullet points.

  </TemplateCard>

  <TemplateCard title="Step-by-Step Guide Template">
    You are an experienced [DOMAIN] instructor known for clear, actionable tutorials.

    Create a beginner-friendly guide for: **[TOPIC]**

    **Structure:**
    - Prerequisites (what they need first)
    - Materials/tools required
    - Steps (numbered, with explanations)
    - Common mistakes to avoid
    - Next steps for continued learning

    **Target audience:** [DESCRIBE_AUDIENCE]
    **Tone:** Encouraging but practical
    **Length:** [WORD_COUNT]

  </TemplateCard>
</TemplateGrid>

For more such templates, visit https://medium.com/@praveenmudalgeri05/prompt-engineering-template-library-bafb0b9261bb

---

## Advanced Techniques That Separate Pros from Beginners

> Pro tip: Start with the simplest approach that works. Add advanced techniques when you need more structure, consistency, or reasoning.

![Advanced Techniques for Prompting](/assets/Screenshot%202025-08-10%20124202.png)

## Setting Up Advanced Prompting with Gemini

Let's build a practical example using one of our templates with the Google Gemini API. For the remaining codes visit the GitHub repository: https://github.com/AI-Brewery/aienglog-codes.git, and look for module1/post2.py file.

### Advanced Prompt Manager Class

```python
import os  # For accessing environment variables like API keys
from dotenv import load_dotenv  # To load variables from a .env file into the environment
from google import genai  # Google's Gemini AI SDK for interacting with the API
from google.genai import types  # For request/response configuration and type definitions

load_dotenv()  # Load environment variables from .env so they can be used in the program

class AdvancedPromptManager:
    def __init__(self):
        # Initialize the Google Generative AI client
        api_key = os.getenv("GEMINI_API_KEY")
        self.client = genai.Client(api_key=api_key)

    def expert_prompt(self, role, task, context="", format_instructions="", thinking=False):
        """
        Create structured prompts using a four-part template:
        Role, Task, Context, and Format Instructions.
        """
        prompt_parts = []

        if role:
            prompt_parts.append(f"[ROLE] {role}")
        if task:
            prompt_parts.append(f"[TASK] {task}")
        if context:
            prompt_parts.append(f"[CONTEXT] {context}")
        if format_instructions:
            prompt_parts.append(f"[FORMAT] {format_instructions}")

        # Combine prompt parts with spacing
        full_prompt = "\n\n".join(prompt_parts)

        # Configure the model, optionally enabling 'thinking'
        config = types.GenerateContentConfig(
            thinking_config=types.ThinkingConfig(
                thinking_budget=0 if not thinking else None
            )
        )

        # Generate response from Gemini model
        response = self.client.models.generate_content(
            model="gemini-2.5-flash",
            contents=full_prompt,
            config=config
        )
        return response.text

    def chain_of_thought(self, problem, steps, context=""):
        """
        Implements chain-of-thought reasoning.
        Guides the model to solve a problem step-by-step.
        """
        role = "You are a logical problem-solver who thinks step-by-step."

        # Construct the task with enumerated steps
        task = f"""
        Solve this problem by thinking through each step clearly:

        Problem: {problem}

        Steps to follow:
        {chr(10).join([f"{i+1}. {step}" for i, step in enumerate(steps)])}

        Show your reasoning for each step before providing the final answer.
        """
        return self.expert_prompt(role, task, context)

# Example usage
if __name__ == "__main__":
    pm = AdvancedPromptManager()
```

### Example: Chain of Thought Problem Solving

```python
problem = "Our mobile app has a 60% user churn rate in the first week. How do we fix this?"
steps = [
    "Identify the main reasons users abandon the app in week 1",
    "Analyze the onboarding flow for friction points",
    "Research what successful apps do differently",
    "Prioritize solutions based on impact vs effort",
    "Create an action plan with metrics"
]
context = "B2C fitness tracking app with 50K monthly downloads, primarily millennial users"

result2 = pm.chain_of_thought(problem, steps, context)
print("Problem Solving Result:")
print(result2)
print("\n" + "="*50 + "\n")
```

## Common Mistakes That Kill Your Prompts

Even with great templates, these mistakes will sabotage your results:

#### 1. Role Confusion

- **Wrong:** "Act as a marketing expert and also a developer and also a designer..."
- **Right:** Pick one expert role per prompt. Chain multiple prompts if you need different expertise.

#### 2. Context Overload

- **Wrong:** Including every possible detail in one massive context section.
- **Right:** Include only the context that directly impacts the task at hand.

#### 3. Vague Format Instructions

- **Wrong:** "Make it look nice."
- **Right:** "Format as a bulleted list with each point containing a bold action item followed by 1-2 sentence explanation."

#### 4. Forgetting Constraints

- **Wrong:** Asking for solutions without mentioning budget, time, or resource limitations.
- **Right:** Always include realistic constraints that mirror real-world conditions.

### The RICE Method for Prompt Optimization

- **R**un the prompt 3 times with identical inputs
- **I**dentify patterns in the outputs (what's consistent vs. random)
- **C**hange one element at a time (role, context, or format)
- **E**valuate improvement using specific criteria

## Next Steps: Building Your Prompt Engineering System

You now have the tools to create prompts that work consistently. Here's how to keep improving:

#### 1. Build Your Template Library

- Start collecting templates that work for your specific use cases. Document what works and what doesn't.

#### 2. Create Role Personas

- Develop a library of expert roles for your domain. The more specific the expertise, the better the results.

#### 3. Establish Testing Processes

- Don't rely on single outputs. Test prompts multiple times and with edge cases.

#### 4. Measure What Matters

- Track metrics like output consistency, time to good result, and how often you need to iterate.

You now have the structured templates and role-based techniques to craft prompts that work consistently. But here's where it gets really interesting: what if you could make AI think step-by-step like a human expert? In our next post, we'll explore how few-shot examples, zero-shot reasoning, and Chain of Thought prompting can unlock the AI's true problem-solving potential—turning simple prompts into powerful reasoning engines.
